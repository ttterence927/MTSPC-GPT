{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ui572274\\AppData\\Roaming\\Python\\Python310\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 10.0.1 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896, 268) (268,)\n"
     ]
    }
   ],
   "source": [
    "from sktime.datasets import load_from_tsfile_to_dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_from_tsfile(file_path, return_y=True):\n",
    "    X, y = load_from_tsfile_to_dataframe(file_path)\n",
    "    X = pd.DataFrame({i: pd.Series(x) for i, x in enumerate(X.iloc[:, 0])})\n",
    "    if return_y:\n",
    "        return X, y\n",
    "    else:\n",
    "        return X\n",
    "\n",
    "\n",
    "# Test the function\n",
    "dname= 'SelfRegulationSCP1'\n",
    "file_path = f'./datasets/{dname}/{dname}_TRAIN.ts'\n",
    "X, y = load_from_tsfile(file_path)\n",
    "print(X.shape, y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896, 293) (293,)\n"
     ]
    }
   ],
   "source": [
    "file_path = f'./datasets/{dname}/{dname}_TEST.ts'\n",
    "X_test, y_test = load_from_tsfile(file_path)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = X.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and return encoded labels\n",
    "y = label_encoder.fit_transform(y)\n",
    "y_test = label_encoder.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_test))\n",
    "\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'binary',  # or 'multiclass' for multi-class classification\n",
    "        'metric': 'binary_logloss',  # or 'multi_logloss' for multi-class classification\n",
    "\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "    }\n",
    "\n",
    "    gbm = lgb.LGBMClassifier(**param)\n",
    "    gbm.fit(X_train, y)\n",
    "    preds = gbm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-08 17:40:34,234]\u001b[0m A new study created in memory with name: no-name-4394b376-623f-48fc-b743-16373328f1bf\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:35,540]\u001b[0m Trial 0 finished with value: 0.7815699658703071 and parameters: {'num_leaves': 126, 'learning_rate': 5.588813005456218e-05, 'n_estimators': 543}. Best is trial 0 with value: 0.7815699658703071.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:36,149]\u001b[0m Trial 1 finished with value: 0.8395904436860068 and parameters: {'num_leaves': 47, 'learning_rate': 0.22904633003128042, 'n_estimators': 500}. Best is trial 1 with value: 0.8395904436860068.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:36,736]\u001b[0m Trial 2 finished with value: 0.5017064846416383 and parameters: {'num_leaves': 7, 'learning_rate': 3.9734908703337973e-07, 'n_estimators': 389}. Best is trial 1 with value: 0.8395904436860068.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:37,888]\u001b[0m Trial 3 finished with value: 0.8156996587030717 and parameters: {'num_leaves': 215, 'learning_rate': 2.9108308094897447e-05, 'n_estimators': 511}. Best is trial 1 with value: 0.8395904436860068.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:38,181]\u001b[0m Trial 4 finished with value: 0.825938566552901 and parameters: {'num_leaves': 107, 'learning_rate': 0.9406295782473238, 'n_estimators': 701}. Best is trial 1 with value: 0.8395904436860068.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:38,475]\u001b[0m Trial 5 finished with value: 0.825938566552901 and parameters: {'num_leaves': 63, 'learning_rate': 0.6357608043501284, 'n_estimators': 528}. Best is trial 1 with value: 0.8395904436860068.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:38,884]\u001b[0m Trial 6 finished with value: 0.5017064846416383 and parameters: {'num_leaves': 229, 'learning_rate': 2.998590916446897e-05, 'n_estimators': 126}. Best is trial 1 with value: 0.8395904436860068.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:40,785]\u001b[0m Trial 7 finished with value: 0.7849829351535836 and parameters: {'num_leaves': 159, 'learning_rate': 4.6450716714637594e-05, 'n_estimators': 940}. Best is trial 1 with value: 0.8395904436860068.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:41,836]\u001b[0m Trial 8 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 255, 'learning_rate': 0.06669656510605596, 'n_estimators': 652}. Best is trial 8 with value: 0.8430034129692833.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:42,110]\u001b[0m Trial 9 finished with value: 0.5017064846416383 and parameters: {'num_leaves': 135, 'learning_rate': 2.7072544653372705e-08, 'n_estimators': 55}. Best is trial 8 with value: 0.8430034129692833.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:44,428]\u001b[0m Trial 10 finished with value: 0.8293515358361775 and parameters: {'num_leaves': 254, 'learning_rate': 0.006555205959595673, 'n_estimators': 981}. Best is trial 8 with value: 0.8430034129692833.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:46,247]\u001b[0m Trial 11 finished with value: 0.8327645051194539 and parameters: {'num_leaves': 27, 'learning_rate': 0.009900905186549193, 'n_estimators': 745}. Best is trial 8 with value: 0.8430034129692833.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:47,101]\u001b[0m Trial 12 finished with value: 0.8395904436860068 and parameters: {'num_leaves': 68, 'learning_rate': 0.021804529945001386, 'n_estimators': 299}. Best is trial 8 with value: 0.8430034129692833.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:48,218]\u001b[0m Trial 13 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 176, 'learning_rate': 0.06402688467439183, 'n_estimators': 691}. Best is trial 8 with value: 0.8430034129692833.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:50,266]\u001b[0m Trial 14 finished with value: 0.7952218430034129 and parameters: {'num_leaves': 188, 'learning_rate': 0.0008275795797263069, 'n_estimators': 760}. Best is trial 8 with value: 0.8430034129692833.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:51,819]\u001b[0m Trial 15 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 190, 'learning_rate': 0.045724294130597226, 'n_estimators': 831}. Best is trial 8 with value: 0.8430034129692833.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:53,507]\u001b[0m Trial 16 finished with value: 0.7918088737201365 and parameters: {'num_leaves': 253, 'learning_rate': 0.0009312757363622382, 'n_estimators': 645}. Best is trial 8 with value: 0.8430034129692833.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:55,836]\u001b[0m Trial 17 finished with value: 0.7918088737201365 and parameters: {'num_leaves': 180, 'learning_rate': 0.0006944553527703333, 'n_estimators': 872}. Best is trial 8 with value: 0.8430034129692833.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:57,610]\u001b[0m Trial 18 finished with value: 0.5017064846416383 and parameters: {'num_leaves': 220, 'learning_rate': 1.6856067022335521e-06, 'n_estimators': 838}. Best is trial 8 with value: 0.8430034129692833.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:40:58,891]\u001b[0m Trial 19 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 202, 'learning_rate': 0.0641007145826619, 'n_estimators': 856}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:00,356]\u001b[0m Trial 20 finished with value: 0.8054607508532423 and parameters: {'num_leaves': 232, 'learning_rate': 0.0026572413242454394, 'n_estimators': 606}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:01,452]\u001b[0m Trial 21 finished with value: 0.8361774744027304 and parameters: {'num_leaves': 189, 'learning_rate': 0.06963795269918492, 'n_estimators': 813}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:02,677]\u001b[0m Trial 22 finished with value: 0.8395904436860068 and parameters: {'num_leaves': 161, 'learning_rate': 0.07992601822646185, 'n_estimators': 900}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:05,211]\u001b[0m Trial 23 finished with value: 0.8327645051194539 and parameters: {'num_leaves': 200, 'learning_rate': 0.020955602305734986, 'n_estimators': 996}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:06,008]\u001b[0m Trial 24 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 163, 'learning_rate': 0.17840613680330455, 'n_estimators': 790}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:06,547]\u001b[0m Trial 25 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 145, 'learning_rate': 0.2760569540986609, 'n_estimators': 789}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:06,980]\u001b[0m Trial 26 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 138, 'learning_rate': 0.4864613808844069, 'n_estimators': 764}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:08,472]\u001b[0m Trial 27 finished with value: 0.8156996587030717 and parameters: {'num_leaves': 106, 'learning_rate': 0.0038907284850347745, 'n_estimators': 692}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:09,627]\u001b[0m Trial 28 finished with value: 0.7815699658703071 and parameters: {'num_leaves': 167, 'learning_rate': 0.00023219752299354502, 'n_estimators': 430}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:10,162]\u001b[0m Trial 29 finished with value: 0.8361774744027304 and parameters: {'num_leaves': 101, 'learning_rate': 0.25926456940436604, 'n_estimators': 909}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:12,454]\u001b[0m Trial 30 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 206, 'learning_rate': 0.020386422267484265, 'n_estimators': 861}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:13,014]\u001b[0m Trial 31 finished with value: 0.8327645051194539 and parameters: {'num_leaves': 147, 'learning_rate': 0.1925904775500562, 'n_estimators': 768}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:13,295]\u001b[0m Trial 32 finished with value: 0.825938566552901 and parameters: {'num_leaves': 118, 'learning_rate': 0.927222230283119, 'n_estimators': 615}. Best is trial 19 with value: 0.8464163822525598.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:14,018]\u001b[0m Trial 33 finished with value: 0.8498293515358362 and parameters: {'num_leaves': 207, 'learning_rate': 0.1441675959946782, 'n_estimators': 937}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:15,307]\u001b[0m Trial 34 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 175, 'learning_rate': 0.09411117700231678, 'n_estimators': 936}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:16,266]\u001b[0m Trial 35 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 206, 'learning_rate': 0.13235613882582445, 'n_estimators': 954}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:16,864]\u001b[0m Trial 36 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 207, 'learning_rate': 0.21241562384130283, 'n_estimators': 957}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:18,597]\u001b[0m Trial 37 finished with value: 0.5017064846416383 and parameters: {'num_leaves': 231, 'learning_rate': 3.7924996179421106e-06, 'n_estimators': 926}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:19,249]\u001b[0m Trial 38 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 212, 'learning_rate': 0.20390247351108595, 'n_estimators': 983}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:20,035]\u001b[0m Trial 39 finished with value: 0.7815699658703071 and parameters: {'num_leaves': 240, 'learning_rate': 0.0024074354893772318, 'n_estimators': 230}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:22,600]\u001b[0m Trial 40 finished with value: 0.8361774744027304 and parameters: {'num_leaves': 197, 'learning_rate': 0.015620739009275166, 'n_estimators': 881}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:23,481]\u001b[0m Trial 41 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 170, 'learning_rate': 0.16016575256099153, 'n_estimators': 963}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:23,917]\u001b[0m Trial 42 finished with value: 0.8293515358361775 and parameters: {'num_leaves': 221, 'learning_rate': 0.5177248048401049, 'n_estimators': 929}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:25,411]\u001b[0m Trial 43 finished with value: 0.8361774744027304 and parameters: {'num_leaves': 208, 'learning_rate': 0.039271681446688696, 'n_estimators': 950}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:26,121]\u001b[0m Trial 44 finished with value: 0.8293515358361775 and parameters: {'num_leaves': 178, 'learning_rate': 0.14504262999055265, 'n_estimators': 995}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:27,834]\u001b[0m Trial 45 finished with value: 0.5017064846416383 and parameters: {'num_leaves': 154, 'learning_rate': 2.6322677056565214e-08, 'n_estimators': 848}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:29,905]\u001b[0m Trial 46 finished with value: 0.8225255972696246 and parameters: {'num_leaves': 240, 'learning_rate': 0.006232483168493204, 'n_estimators': 729}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:30,267]\u001b[0m Trial 47 finished with value: 0.8293515358361775 and parameters: {'num_leaves': 181, 'learning_rate': 0.9388972997672834, 'n_estimators': 883}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:31,699]\u001b[0m Trial 48 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 198, 'learning_rate': 0.04032983788039747, 'n_estimators': 823}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:32,663]\u001b[0m Trial 49 finished with value: 0.8395904436860068 and parameters: {'num_leaves': 126, 'learning_rate': 0.11498663409629802, 'n_estimators': 938}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:35,175]\u001b[0m Trial 50 finished with value: 0.5017064846416383 and parameters: {'num_leaves': 214, 'learning_rate': 1.306756108495536e-07, 'n_estimators': 954}. Best is trial 33 with value: 0.8498293515358362.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:35,864]\u001b[0m Trial 51 finished with value: 0.863481228668942 and parameters: {'num_leaves': 191, 'learning_rate': 0.4117942969579083, 'n_estimators': 801}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:36,378]\u001b[0m Trial 52 finished with value: 0.8327645051194539 and parameters: {'num_leaves': 197, 'learning_rate': 0.44331567353366524, 'n_estimators': 813}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:38,286]\u001b[0m Trial 53 finished with value: 0.8327645051194539 and parameters: {'num_leaves': 225, 'learning_rate': 0.031162147819055228, 'n_estimators': 712}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:39,923]\u001b[0m Trial 54 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 186, 'learning_rate': 0.048598067964157055, 'n_estimators': 804}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:40,731]\u001b[0m Trial 55 finished with value: 0.8361774744027304 and parameters: {'num_leaves': 3, 'learning_rate': 0.010014167678510176, 'n_estimators': 904}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:41,904]\u001b[0m Trial 56 finished with value: 0.8395904436860068 and parameters: {'num_leaves': 243, 'learning_rate': 0.09290409131876887, 'n_estimators': 472}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:43,439]\u001b[0m Trial 57 finished with value: 0.8395904436860068 and parameters: {'num_leaves': 188, 'learning_rate': 0.039319909011221454, 'n_estimators': 794}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:43,932]\u001b[0m Trial 58 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 216, 'learning_rate': 0.3447357753730127, 'n_estimators': 862}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:45,634]\u001b[0m Trial 59 finished with value: 0.8395904436860068 and parameters: {'num_leaves': 162, 'learning_rate': 0.011357370565181619, 'n_estimators': 660}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:47,512]\u001b[0m Trial 60 finished with value: 0.7849829351535836 and parameters: {'num_leaves': 173, 'learning_rate': 0.00010026343445978928, 'n_estimators': 742}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:48,549]\u001b[0m Trial 61 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 200, 'learning_rate': 0.10496113732020558, 'n_estimators': 1000}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:50,128]\u001b[0m Trial 62 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 193, 'learning_rate': 0.043989365891508335, 'n_estimators': 999}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:50,689]\u001b[0m Trial 63 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 206, 'learning_rate': 0.2841076351578464, 'n_estimators': 898}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:51,045]\u001b[0m Trial 64 finished with value: 0.8191126279863481 and parameters: {'num_leaves': 208, 'learning_rate': 0.5652323743501061, 'n_estimators': 565}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:51,998]\u001b[0m Trial 65 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 151, 'learning_rate': 0.072910397964105, 'n_estimators': 796}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:54,149]\u001b[0m Trial 66 finished with value: 0.8361774744027304 and parameters: {'num_leaves': 183, 'learning_rate': 0.02658475669408881, 'n_estimators': 832}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:54,722]\u001b[0m Trial 67 finished with value: 0.8395904436860068 and parameters: {'num_leaves': 226, 'learning_rate': 0.36351890964566863, 'n_estimators': 965}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:55,894]\u001b[0m Trial 68 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 205, 'learning_rate': 0.0963973305635038, 'n_estimators': 906}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:56,522]\u001b[0m Trial 69 finished with value: 0.5017064846416383 and parameters: {'num_leaves': 78, 'learning_rate': 1.1190529717180884e-05, 'n_estimators': 316}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:56,885]\u001b[0m Trial 70 finished with value: 0.8395904436860068 and parameters: {'num_leaves': 170, 'learning_rate': 0.8620521469471177, 'n_estimators': 899}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:57,853]\u001b[0m Trial 71 finished with value: 0.8361774744027304 and parameters: {'num_leaves': 201, 'learning_rate': 0.11069735223294323, 'n_estimators': 910}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:59,008]\u001b[0m Trial 72 finished with value: 0.8395904436860068 and parameters: {'num_leaves': 188, 'learning_rate': 0.06450033940926325, 'n_estimators': 860}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:41:59,915]\u001b[0m Trial 73 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 216, 'learning_rate': 0.172258904315892, 'n_estimators': 831}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:00,605]\u001b[0m Trial 74 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 234, 'learning_rate': 0.23438284818801983, 'n_estimators': 889}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:01,193]\u001b[0m Trial 75 finished with value: 0.856655290102389 and parameters: {'num_leaves': 218, 'learning_rate': 0.3539425908817415, 'n_estimators': 928}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:01,697]\u001b[0m Trial 76 finished with value: 0.8327645051194539 and parameters: {'num_leaves': 220, 'learning_rate': 0.32243626336485914, 'n_estimators': 782}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:02,176]\u001b[0m Trial 77 finished with value: 0.8498293515358362 and parameters: {'num_leaves': 184, 'learning_rate': 0.391718672762637, 'n_estimators': 978}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:04,493]\u001b[0m Trial 78 finished with value: 0.8498293515358362 and parameters: {'num_leaves': 193, 'learning_rate': 0.019573066906131465, 'n_estimators': 930}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:04,799]\u001b[0m Trial 79 finished with value: 0.8361774744027304 and parameters: {'num_leaves': 165, 'learning_rate': 0.5913415720060189, 'n_estimators': 64}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:06,848]\u001b[0m Trial 80 finished with value: 0.5017064846416383 and parameters: {'num_leaves': 34, 'learning_rate': 1.1011193842768509e-08, 'n_estimators': 978}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:07,741]\u001b[0m Trial 81 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 185, 'learning_rate': 0.31084747440979055, 'n_estimators': 927}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:08,308]\u001b[0m Trial 82 finished with value: 0.8293515358361775 and parameters: {'num_leaves': 192, 'learning_rate': 0.67776808773201, 'n_estimators': 931}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:08,863]\u001b[0m Trial 83 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 209, 'learning_rate': 0.231557041519159, 'n_estimators': 971}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:09,607]\u001b[0m Trial 84 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 177, 'learning_rate': 0.13583565894724264, 'n_estimators': 957}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:10,060]\u001b[0m Trial 85 finished with value: 0.8361774744027304 and parameters: {'num_leaves': 200, 'learning_rate': 0.45757977886701867, 'n_estimators': 989}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:10,657]\u001b[0m Trial 86 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 217, 'learning_rate': 0.18685843024434143, 'n_estimators': 833}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:11,105]\u001b[0m Trial 87 finished with value: 0.8156996587030717 and parameters: {'num_leaves': 245, 'learning_rate': 0.9875759347894658, 'n_estimators': 869}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:13,629]\u001b[0m Trial 88 finished with value: 0.8225255972696246 and parameters: {'num_leaves': 232, 'learning_rate': 0.004289565166130119, 'n_estimators': 942}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:15,688]\u001b[0m Trial 89 finished with value: 0.8498293515358362 and parameters: {'num_leaves': 223, 'learning_rate': 0.023296760828173856, 'n_estimators': 918}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:18,187]\u001b[0m Trial 90 finished with value: 0.8293515358361775 and parameters: {'num_leaves': 224, 'learning_rate': 0.013532813658032715, 'n_estimators': 919}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:19,593]\u001b[0m Trial 91 finished with value: 0.8498293515358362 and parameters: {'num_leaves': 205, 'learning_rate': 0.058729730803349804, 'n_estimators': 964}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:21,645]\u001b[0m Trial 92 finished with value: 0.8327645051194539 and parameters: {'num_leaves': 193, 'learning_rate': 0.01610291497085174, 'n_estimators': 947}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:23,482]\u001b[0m Trial 93 finished with value: 0.8020477815699659 and parameters: {'num_leaves': 212, 'learning_rate': 0.0012332888298402962, 'n_estimators': 973}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:24,516]\u001b[0m Trial 94 finished with value: 0.8532423208191127 and parameters: {'num_leaves': 210, 'learning_rate': 0.06018732192036723, 'n_estimators': 977}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:25,925]\u001b[0m Trial 95 finished with value: 0.8464163822525598 and parameters: {'num_leaves': 195, 'learning_rate': 0.03036141068867551, 'n_estimators': 880}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:27,884]\u001b[0m Trial 96 finished with value: 0.8191126279863481 and parameters: {'num_leaves': 177, 'learning_rate': 0.00744496096234944, 'n_estimators': 923}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:29,559]\u001b[0m Trial 97 finished with value: 0.8293515358361775 and parameters: {'num_leaves': 183, 'learning_rate': 0.02174045171812164, 'n_estimators': 934}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:30,347]\u001b[0m Trial 98 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 236, 'learning_rate': 0.0725690061282029, 'n_estimators': 849}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:42:31,548]\u001b[0m Trial 99 finished with value: 0.8430034129692833 and parameters: {'num_leaves': 203, 'learning_rate': 0.053828615918246184, 'n_estimators': 888}. Best is trial 51 with value: 0.863481228668942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial: {'num_leaves': 191, 'learning_rate': 0.4117942969579083, 'n_estimators': 801}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
