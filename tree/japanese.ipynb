{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading EthanolConcentration: File is not a zip file\n",
      "Error downloading FaceDetection: File is not a zip file\n",
      "Error downloading Handwriting: File is not a zip file\n",
      "Error downloading Heartbeat: File is not a zip file\n",
      "Error downloading JapaneseVowels: File is not a zip file\n",
      "Error downloading PEMS-SF: File is not a zip file\n",
      "Error downloading SelfRegulationSCP1: File is not a zip file\n",
      "Error downloading SelfRegulationSCP2: File is not a zip file\n",
      "Error downloading SpokenArabicDigits: File is not a zip file\n",
      "Error downloading UWaveGestureLibrary: File is not a zip file\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# List of UEA datasets to download\n",
    "datasets = [\n",
    "    'EthanolConcentration', 'FaceDetection', 'Handwriting', 'Heartbeat',\n",
    "    'JapaneseVowels', 'PEMS-SF', 'SelfRegulationSCP1', 'SelfRegulationSCP2',\n",
    "    'SpokenArabicDigits', 'UWaveGestureLibrary'\n",
    "]\n",
    "\n",
    "# Base URL for downloading the datasets\n",
    "base_url = \"https://www.timeseriesclassification.com/aeon-toolkit/\"\n",
    "\n",
    "# Create a directory for the downloaded datasets if it doesn't exist\n",
    "os.makedirs('datasets', exist_ok=True)\n",
    "\n",
    "# Download each dataset\n",
    "for dataset in datasets:\n",
    "    # Construct the URL for the dataset\n",
    "    dataset_url = f\"{base_url}{dataset}.zip\"\n",
    "    \n",
    "    # Make the request to download the dataset\n",
    "    response = requests.get(dataset_url, verify=False)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Save the dataset to a file\n",
    "        filename = os.path.join('UEA_datasets', f\"{dataset}.zip\")\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {dataset}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {dataset}: Status code {response.status_code}\")\n",
    "\n",
    "# Note: This code assumes that the datasets are available at the given URL pattern.\n",
    "# If the URL pattern is incorrect, the downloads will fail.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 270) (270,)\n"
     ]
    }
   ],
   "source": [
    "from sktime.datasets import load_from_tsfile_to_dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_from_tsfile(file_path, return_y=True):\n",
    "    X, y = load_from_tsfile_to_dataframe(file_path)\n",
    "    X = pd.DataFrame({i: pd.Series(x) for i, x in enumerate(X.iloc[:, 0])})\n",
    "    if return_y:\n",
    "        return X, y\n",
    "    else:\n",
    "        return X\n",
    "\n",
    "\n",
    "# Test the function\n",
    "file_path = './datasets/JapaneseVowels/JapaneseVowels_TRAIN.ts'\n",
    "X, y = load_from_tsfile(file_path)\n",
    "print(X.shape, y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 370) (370,)\n"
     ]
    }
   ],
   "source": [
    "file_path = './datasets/JapaneseVowels/JapaneseVowels_TEST.ts'\n",
    "X_test, y_test = load_from_tsfile(file_path)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2',\n",
       "       '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2',\n",
       "       '2', '2', '2', '2', '2', '2', '2', '2', '3', '3', '3', '3', '3',\n",
       "       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',\n",
       "       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '4',\n",
       "       '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4',\n",
       "       '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4',\n",
       "       '4', '4', '4', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5',\n",
       "       '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5',\n",
       "       '5', '5', '5', '5', '5', '5', '5', '6', '6', '6', '6', '6', '6',\n",
       "       '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6',\n",
       "       '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '7', '7',\n",
       "       '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7',\n",
       "       '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7',\n",
       "       '7', '7', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8',\n",
       "       '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8',\n",
       "       '8', '8', '8', '8', '8', '8', '9', '9', '9', '9', '9', '9', '9',\n",
       "       '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "       '9', '9', '9', '9', '9', '9', '9', '9', '9', '9'], dtype='<U1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = X.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2',\n",
       "       '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2',\n",
       "       '2', '2', '2', '2', '2', '2', '2', '2', '3', '3', '3', '3', '3',\n",
       "       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3',\n",
       "       '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '4',\n",
       "       '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4',\n",
       "       '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4', '4',\n",
       "       '4', '4', '4', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5',\n",
       "       '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5', '5',\n",
       "       '5', '5', '5', '5', '5', '5', '5', '6', '6', '6', '6', '6', '6',\n",
       "       '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6',\n",
       "       '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '7', '7',\n",
       "       '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7',\n",
       "       '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7',\n",
       "       '7', '7', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8',\n",
       "       '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8',\n",
       "       '8', '8', '8', '8', '8', '8', '9', '9', '9', '9', '9', '9', '9',\n",
       "       '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9',\n",
       "       '9', '9', '9', '9', '9', '9', '9', '9', '9', '9'], dtype='<U1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.iloc[:, :26]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'multiclass',  # or 'multiclass' for multi-class classification\n",
    "        'metric': 'multi_logloss',  # or 'multi_logloss' for multi-class classification\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "    }\n",
    "\n",
    "    gbm = lgb.LGBMClassifier(**param)\n",
    "    gbm.fit(X_train, y)\n",
    "    preds = gbm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-08 17:25:21,275]\u001b[0m A new study created in memory with name: no-name-299c7f46-f756-4e55-b031-743f11daab37\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:22,561]\u001b[0m Trial 0 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 118, 'learning_rate': 1.9073863075115233e-06, 'n_estimators': 569}. Best is trial 0 with value: 0.5243243243243243.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:23,621]\u001b[0m Trial 1 finished with value: 0.572972972972973 and parameters: {'num_leaves': 142, 'learning_rate': 0.0001681096073458359, 'n_estimators': 555}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:25,493]\u001b[0m Trial 2 finished with value: 0.5702702702702702 and parameters: {'num_leaves': 238, 'learning_rate': 0.0001463594221872099, 'n_estimators': 978}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:26,204]\u001b[0m Trial 3 finished with value: 0.518918918918919 and parameters: {'num_leaves': 3, 'learning_rate': 1.4236015354497582e-07, 'n_estimators': 801}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:28,144]\u001b[0m Trial 4 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 222, 'learning_rate': 2.5645282540150084e-07, 'n_estimators': 987}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:29,932]\u001b[0m Trial 5 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 77, 'learning_rate': 8.206006070204836e-06, 'n_estimators': 977}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:30,841]\u001b[0m Trial 6 finished with value: 0.5513513513513514 and parameters: {'num_leaves': 123, 'learning_rate': 0.03648000265605146, 'n_estimators': 490}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:32,563]\u001b[0m Trial 7 finished with value: 0.572972972972973 and parameters: {'num_leaves': 39, 'learning_rate': 0.00011608617242615353, 'n_estimators': 686}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:34,082]\u001b[0m Trial 8 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 235, 'learning_rate': 8.703170110659936e-08, 'n_estimators': 533}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:35,976]\u001b[0m Trial 9 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 217, 'learning_rate': 3.6199032131326214e-08, 'n_estimators': 868}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:36,326]\u001b[0m Trial 10 finished with value: 0.5486486486486486 and parameters: {'num_leaves': 173, 'learning_rate': 0.020413881419621055, 'n_estimators': 157}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:36,938]\u001b[0m Trial 11 finished with value: 0.5567567567567567 and parameters: {'num_leaves': 45, 'learning_rate': 0.0009366421065583557, 'n_estimators': 339}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:38,392]\u001b[0m Trial 12 finished with value: 0.572972972972973 and parameters: {'num_leaves': 163, 'learning_rate': 0.001038351130303261, 'n_estimators': 698}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:38,643]\u001b[0m Trial 13 finished with value: 0.5432432432432432 and parameters: {'num_leaves': 82, 'learning_rate': 0.8365089540796559, 'n_estimators': 358}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:40,532]\u001b[0m Trial 14 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 156, 'learning_rate': 2.3590974719998524e-05, 'n_estimators': 672}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:41,234]\u001b[0m Trial 15 finished with value: 0.5702702702702702 and parameters: {'num_leaves': 15, 'learning_rate': 0.0004709785940681069, 'n_estimators': 353}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:42,966]\u001b[0m Trial 16 finished with value: 0.5378378378378378 and parameters: {'num_leaves': 73, 'learning_rate': 0.008435488311513842, 'n_estimators': 693}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:44,856]\u001b[0m Trial 17 finished with value: 0.5594594594594594 and parameters: {'num_leaves': 182, 'learning_rate': 0.0024445628661891846, 'n_estimators': 789}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:45,173]\u001b[0m Trial 18 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 98, 'learning_rate': 3.098476922460144e-05, 'n_estimators': 118}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:45,217]\u001b[0m Trial 19 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 40, 'learning_rate': 1.4714172372325338e-06, 'n_estimators': 12}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:45,655]\u001b[0m Trial 20 finished with value: 0.5297297297297298 and parameters: {'num_leaves': 140, 'learning_rate': 0.23541134767417218, 'n_estimators': 446}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:46,902]\u001b[0m Trial 21 finished with value: 0.572972972972973 and parameters: {'num_leaves': 170, 'learning_rate': 0.00018214364984135508, 'n_estimators': 668}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:48,518]\u001b[0m Trial 22 finished with value: 0.5540540540540541 and parameters: {'num_leaves': 191, 'learning_rate': 0.003488901866172278, 'n_estimators': 608}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:49,909]\u001b[0m Trial 23 finished with value: 0.5621621621621622 and parameters: {'num_leaves': 155, 'learning_rate': 0.0003590379317357227, 'n_estimators': 777}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:51,230]\u001b[0m Trial 24 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 196, 'learning_rate': 2.6257417129690973e-05, 'n_estimators': 603}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:52,497]\u001b[0m Trial 25 finished with value: 0.5675675675675675 and parameters: {'num_leaves': 158, 'learning_rate': 0.0018708542286731042, 'n_estimators': 453}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:54,849]\u001b[0m Trial 26 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 135, 'learning_rate': 7.447905992014665e-06, 'n_estimators': 885}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:55,994]\u001b[0m Trial 27 finished with value: 0.5513513513513514 and parameters: {'num_leaves': 205, 'learning_rate': 0.0561100336271588, 'n_estimators': 725}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:57,192]\u001b[0m Trial 28 finished with value: 0.5621621621621622 and parameters: {'num_leaves': 111, 'learning_rate': 9.444025791492254e-05, 'n_estimators': 642}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:58,269]\u001b[0m Trial 29 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 99, 'learning_rate': 1.5093422624883292e-06, 'n_estimators': 561}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:25:58,910]\u001b[0m Trial 30 finished with value: 0.5297297297297298 and parameters: {'num_leaves': 52, 'learning_rate': 9.570128951765258e-05, 'n_estimators': 268}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:00,342]\u001b[0m Trial 31 finished with value: 0.5621621621621622 and parameters: {'num_leaves': 170, 'learning_rate': 0.00028467271346081314, 'n_estimators': 733}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:01,998]\u001b[0m Trial 32 finished with value: 0.572972972972973 and parameters: {'num_leaves': 143, 'learning_rate': 8.131191365881279e-05, 'n_estimators': 857}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:03,699]\u001b[0m Trial 33 finished with value: 0.5675675675675675 and parameters: {'num_leaves': 145, 'learning_rate': 0.0009157387493591746, 'n_estimators': 869}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:05,844]\u001b[0m Trial 34 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 122, 'learning_rate': 9.375368278662517e-06, 'n_estimators': 826}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:07,511]\u001b[0m Trial 35 finished with value: 0.572972972972973 and parameters: {'num_leaves': 109, 'learning_rate': 0.00010260111556851862, 'n_estimators': 928}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:09,158]\u001b[0m Trial 36 finished with value: 0.5594594594594594 and parameters: {'num_leaves': 106, 'learning_rate': 6.094129810746552e-05, 'n_estimators': 929}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:10,604]\u001b[0m Trial 37 finished with value: 0.5432432432432432 and parameters: {'num_leaves': 250, 'learning_rate': 0.006513822982699481, 'n_estimators': 487}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:11,907]\u001b[0m Trial 38 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 87, 'learning_rate': 5.489247015604265e-06, 'n_estimators': 632}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:13,686]\u001b[0m Trial 39 finished with value: 0.5702702702702702 and parameters: {'num_leaves': 64, 'learning_rate': 0.001058527642248201, 'n_estimators': 917}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:16,237]\u001b[0m Trial 40 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 21, 'learning_rate': 4.476409073279269e-07, 'n_estimators': 991}. Best is trial 1 with value: 0.572972972972973.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:17,624]\u001b[0m Trial 41 finished with value: 0.5783783783783784 and parameters: {'num_leaves': 128, 'learning_rate': 0.00015913248536304547, 'n_estimators': 749}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:19,250]\u001b[0m Trial 42 finished with value: 0.5648648648648649 and parameters: {'num_leaves': 129, 'learning_rate': 0.00023025264725328677, 'n_estimators': 818}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:20,948]\u001b[0m Trial 43 finished with value: 0.5513513513513514 and parameters: {'num_leaves': 146, 'learning_rate': 4.8174071705954085e-05, 'n_estimators': 909}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:22,357]\u001b[0m Trial 44 finished with value: 0.572972972972973 and parameters: {'num_leaves': 118, 'learning_rate': 0.00017730455785229727, 'n_estimators': 753}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:23,635]\u001b[0m Trial 45 finished with value: 0.5621621621621622 and parameters: {'num_leaves': 116, 'learning_rate': 0.0004919738713825987, 'n_estimators': 740}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:25,122]\u001b[0m Trial 46 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 117, 'learning_rate': 1.8992533645601077e-05, 'n_estimators': 839}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:26,844]\u001b[0m Trial 47 finished with value: 0.5675675675675675 and parameters: {'num_leaves': 166, 'learning_rate': 0.000787158434705474, 'n_estimators': 683}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:27,794]\u001b[0m Trial 48 finished with value: 0.5756756756756757 and parameters: {'num_leaves': 175, 'learning_rate': 0.00018596170159969588, 'n_estimators': 541}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:28,850]\u001b[0m Trial 49 finished with value: 0.5405405405405406 and parameters: {'num_leaves': 180, 'learning_rate': 0.009583324711780113, 'n_estimators': 521}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:30,279]\u001b[0m Trial 50 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 218, 'learning_rate': 3.2398650780915014e-06, 'n_estimators': 760}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:31,029]\u001b[0m Trial 51 finished with value: 0.572972972972973 and parameters: {'num_leaves': 138, 'learning_rate': 0.00016685986291501431, 'n_estimators': 423}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:31,787]\u001b[0m Trial 52 finished with value: 0.5675675675675675 and parameters: {'num_leaves': 129, 'learning_rate': 0.0001627818403081854, 'n_estimators': 400}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:33,503]\u001b[0m Trial 53 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 152, 'learning_rate': 1.3590698945717632e-05, 'n_estimators': 967}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:34,447]\u001b[0m Trial 54 finished with value: 0.527027027027027 and parameters: {'num_leaves': 92, 'learning_rate': 4.150818684083356e-05, 'n_estimators': 546}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:35,505]\u001b[0m Trial 55 finished with value: 0.5621621621621622 and parameters: {'num_leaves': 70, 'learning_rate': 0.00046305396500502185, 'n_estimators': 600}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:36,789]\u001b[0m Trial 56 finished with value: 0.5567567567567567 and parameters: {'num_leaves': 164, 'learning_rate': 0.003405985320369987, 'n_estimators': 701}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:37,344]\u001b[0m Trial 57 finished with value: 0.5567567567567567 and parameters: {'num_leaves': 182, 'learning_rate': 0.001081667766757721, 'n_estimators': 295}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:38,637]\u001b[0m Trial 58 finished with value: 0.5702702702702702 and parameters: {'num_leaves': 203, 'learning_rate': 0.0020492056371784286, 'n_estimators': 653}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:39,720]\u001b[0m Trial 59 finished with value: 0.572972972972973 and parameters: {'num_leaves': 108, 'learning_rate': 0.00016409844069307998, 'n_estimators': 582}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:40,842]\u001b[0m Trial 60 finished with value: 0.5594594594594594 and parameters: {'num_leaves': 100, 'learning_rate': 9.93441637729907e-05, 'n_estimators': 575}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:41,752]\u001b[0m Trial 61 finished with value: 0.5378378378378378 and parameters: {'num_leaves': 130, 'learning_rate': 6.326254493713507e-05, 'n_estimators': 507}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:43,389]\u001b[0m Trial 62 finished with value: 0.5675675675675675 and parameters: {'num_leaves': 107, 'learning_rate': 0.0003547972194714081, 'n_estimators': 951}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:44,077]\u001b[0m Trial 63 finished with value: 0.5243243243243243 and parameters: {'num_leaves': 16, 'learning_rate': 3.0707832482994326e-05, 'n_estimators': 395}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:45,814]\u001b[0m Trial 64 finished with value: 0.5621621621621622 and parameters: {'num_leaves': 178, 'learning_rate': 7.789626871687215e-05, 'n_estimators': 787}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:47,394]\u001b[0m Trial 65 finished with value: 0.5648648648648649 and parameters: {'num_leaves': 143, 'learning_rate': 0.0002450454972963495, 'n_estimators': 860}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[32m[I 2024-02-08 17:26:48,948]\u001b[0m Trial 66 finished with value: 0.5702702702702702 and parameters: {'num_leaves': 138, 'learning_rate': 0.0006420336411795489, 'n_estimators': 804}. Best is trial 41 with value: 0.5783783783783784.\u001b[0m\n",
      "\u001b[33m[W 2024-02-08 17:26:49,788]\u001b[0m Trial 67 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ui572274\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\ui572274\\AppData\\Local\\Temp\\1\\ipykernel_4164\\818207970.py\", line 17, in objective\n",
      "    gbm.fit(X_train, y)\n",
      "  File \"C:\\Users\\ui572274\\AppData\\Roaming\\Python\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"C:\\Users\\ui572274\\AppData\\Roaming\\Python\\Python310\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\ui572274\\AppData\\Roaming\\Python\\Python310\\site-packages\\lightgbm\\engine.py\", line 292, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"C:\\Users\\ui572274\\AppData\\Roaming\\Python\\Python310\\site-packages\\lightgbm\\basic.py\", line 3021, in update\n",
      "    _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of finished trials:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mtrials))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m'\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[23], line 17\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      6\u001b[0m param \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# or 'multiclass' for multi-class classification\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti_logloss\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# or 'multi_logloss' for multi-class classification\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1000\u001b[39m),\n\u001b[0;32m     14\u001b[0m }\n\u001b[0;32m     16\u001b[0m gbm \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m preds \u001b[38;5;241m=\u001b[39m gbm\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     19\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, preds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\lightgbm\\sklearn.py:967\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m             valid_sets[i] \u001b[38;5;241m=\u001b[39m (valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y))\n\u001b[1;32m--> 967\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\lightgbm\\engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    285\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m    286\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    287\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[0;32m    288\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[0;32m    289\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[0;32m    290\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m--> 292\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m evaluation_result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\lightgbm\\basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 3021\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
